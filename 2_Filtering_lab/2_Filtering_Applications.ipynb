{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfaaf413",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e930c19ce8395f7b42e77c947d3f626",
     "grade": false,
     "grade_id": "cell-e10e94761156144f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" style=\"padding-right:10px;width:140px;float:left\"></td>\n",
    "<h2 style=\"white-space: nowrap\">Image Processing Laboratory Notebooks</h2>\n",
    "<hr style=\"clear:both\">\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "This Juypter notebook is part of a series of computer laboratories which are designed\n",
    "to teach image-processing programming; they are running on the EPFL's Noto server. They are the practical complement of the theoretical lectures of the EPFL's Master course <b>Image Processing I</b> \n",
    "(<a href=\"https://moodle.epfl.ch/course/view.php?id=522\">MICRO-511</a>) taught by Prof. M. Unser and Prof. D. Van de Ville.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "The project is funded by the Center for Digital Education and the School of Engineering. It is owned by the <a href=\"http://bigwww.epfl.ch/\">Biomedical Imaging Group</a>. \n",
    "The distribution or the reproduction of the notebook is strictly prohibited without the written consent of the authors.  &copy; EPFL <mark>2021</mark>.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:0px\"><b>Authors</b>: \n",
    "    <a href=\"mailto:pol.delaguilapla@epfl.ch\">Pol del Aguila Pla</a>, \n",
    "    <a href=\"mailto:kay.lachler@epfl.ch\">Kay L\u00e4chler</a>,\n",
    "    <a href=\"mailto:alejandro.nogueronaramburu@epfl.ch\">Alejandro Noguer\u00f3n Ar\u00e1mburu</a>, and\n",
    "    <a href=\"mailto:daniel.sage@epfl.ch\">Daniel Sage</a>.\n",
    "</p>\n",
    "<hr style=\"clear:both\">\n",
    "<h1>Lab 2.2: Filtering Applications</h1>\n",
    "<div style=\"background-color:#F0F0F0;padding:4px\">\n",
    "    <p style=\"margin:4px;\"><b>Released</b>: <mark>Thursday November 10, 2022</mark></p>\n",
    "    <p style=\"margin:4px;\"><b>Submission</b>: <mark><span style=\"color:red\">Friday November 18, 2022</span></mark> (before 11:59PM) on <a href=\"https://moodle.epfl.ch/course/view.php?id=522\">Moodle</a></p>\n",
    "    <p style=\"margin:4px;\"><b>Grade weight</b>: Lab 2 (<mark>16</mark> points), 10% of the overall grade</p>\n",
    "    <p style=\"margin:4px;\"><b>Help sessions</b>: <mark>Thursday November 17</mark> on campus</p>        \n",
    "    <p style=\"margin:4px;\"><b>Related lectures</b>: Chapter 3</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e959a7",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Student Name: \n",
    "### SCIPER: \n",
    "\n",
    "Double-click on this cell and fill your name and SCIPER number. Then, run the cell below to verify your identity in Noto and set the seed for random results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fe3071",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b3cbfd60b113917b736a4c730ea0749",
     "grade": true,
     "grade_id": "cell-db23f05a9669b9df",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "import getpass\n",
    "# This line recovers your camipro number to mark the images with your ID\n",
    "uid = int(getpass.getuser().split('-')[2]) if len(getpass.getuser().split('-')) > 2 else ord(getpass.getuser()[0])\n",
    "print(f'SCIPER: {uid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc76ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbc4e325f9682d975462e423fdb0bcb4",
     "grade": false,
     "grade_id": "cell-30f20696e62cadde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <a name=\"imports_\"></a> Imports\n",
    "In the next cell we import the Python libraries that we will use throughout the lab, as well as the `ImageViewer` class (Python package developed specifically for these laboratories, see documentation [here](https://github.com/Biomedical-Imaging-Group/interactive-kit/wiki/Image-Viewer), or run the python command `help(viewer)` after loading the class):\n",
    "\n",
    "* [`matplotlib.pyplot`](https://matplotlib.org), to display images\n",
    "* [`ipywidgets`](https://ipywidgets.readthedocs.io/en/latest/), to make the image display interactive\n",
    "* [`numpy`](https://numpy.org/doc/stable/reference/index.html), for mathematical operations on arrays\n",
    "* [`openCV` (cv2)](https://docs.opencv.org/2.4/index.html), for image-processing tasks\n",
    "* [`scipy.ndimage`](https://docs.scipy.org/doc/scipy/reference/ndimage.html), Scipy's specific module for multidimensional image processing\n",
    "* [`scikit-image` (skimage)](https://scikit-image.org/docs/stable/api/api.html), also for image-processing tasks\n",
    "\n",
    "We will then load the `ImageViewer` class (either see the complete documentation [here](https://github.com/Biomedical-Imaging-Group/interactive-kit/wiki/Image-Viewer), run the Python command `help(viewer)` after loading the class, or refer to [Lab 0: Introduction](../0_Introductory_lab/Introductory.ipynb#4.-Python-Image-Viewer)).\n",
    "\n",
    "Finally, we load the images you will use in the exercise to test your algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7547ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18c0a4618f498092b613114bd2fe6344",
     "grade": false,
     "grade_id": "cell-83da6ef721c33a1d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Configure plotting as dynamic\n",
    "%matplotlib widget\n",
    "\n",
    "# Import standard required packages for this exercise\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv \n",
    "import scipy.ndimage as ndi\n",
    "import ipywidgets as widgets\n",
    "import skimage\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from skimage import filters\n",
    "from interactive_kit import imviewer as viewer\n",
    "\n",
    "# Load images to be used in this exercise \n",
    "bikesgray = cv.imread('images/bikesgray.tif', cv.IMREAD_UNCHANGED).astype('float64')\n",
    "\n",
    "# Import the whole stack of 1200 images from camera-16bits.tif\n",
    "from skimage import io\n",
    "camera = io.imread(\"images/camera-16bits.tif\").astype(np.float64)\n",
    "# # We extract one of the images as a test image\n",
    "camera_test = camera[55]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b64241",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c30fb69a552f362ae7580c9c34b9301d",
     "grade": false,
     "grade_id": "cell-3afa80c87650faf6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we will import the `ImageAccess` class. You can find the documentation of the class [here](https://biomedical-imaging-group.github.io/image-access/). Moreover, we will put the images we will be using in the JavaScript kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c77c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d19f68039a5b1e09d38e9d1088a0c22c",
     "grade": true,
     "grade_id": "cell-e11cc8f86428e3ed",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get bikesgray camera_test\n",
    "// import IPLabImageAccess as Image\n",
    "var Image = require('image-access')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d674d688",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e40993a3800b5c4473049b383fa58658",
     "grade": false,
     "grade_id": "cell-ef8475e06d169d95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Filtering applications (7 points)\n",
    "\n",
    "After the [first part](./1_Filtering.ipynb) of the lab, we expect you to feel comfortable with the basics of filtering. In this part we will look in the detail at the implementation of a Gaussian filter, as well as some of its direct applications. Gaussian filters are known to be near-optimal smoothing filters, and represent perhaps the most used preprocessing step in image processing to improve robustness in a workflow and to denoise images.\n",
    "\n",
    "## <a id=\"ToC_2_FilteringApplications\"></a>Table of contents\n",
    "1. [Gaussian filter](#1.-Gaussian-filter-(4-points))\n",
    "    1. [Implementation of a 2D Gaussian filter](#1.A.-Implementation-of-a-2D-Gaussian-filter-(4-points)) (**4 points**)\n",
    "    2. [Gaussian filter in Python](#1.B.-Gaussian-filter-in-Python)\n",
    "4. [Application: Super-resolution localization microscopy](#2.-Application:-Super-resolution-localization-microscopy-(3-points))\n",
    "    1. [Difference of Gaussians](#2.A.-Difference-of-Gaussians-(1-points)) (**1 points**)\n",
    "    2. [Local maxima](#2.B.-Local-maxima-(1-point)) (**1 point**)\n",
    "    3. [Center of gravity](#2.C.-Center-of-gravity-(1-point)) (**1 point**)\n",
    "    4. [Complete localization pipeline](#2.D.-Complete-localization-pipeline)\n",
    "\n",
    "<div class=\" alert alert-danger\">\n",
    "\n",
    "<b>Important:</b> Each cell that contains code begins with `%use sos` or `%use javascript`. This indicates if the code in this specific cell should be written in Python or JavaScript. Do not change or remove any lines of code that begin with an %. They are used for the notebook to run smoothly with <code>SoS</code> and need to be on the first line of each cell!\n",
    "</div>\n",
    "\n",
    "Good luck and enjoy! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd6cfa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38fba4e44870bac4cf52ddf98524e911",
     "grade": false,
     "grade_id": "cell-ef614255c73b3afc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualize images\n",
    "Get familiar now with the images you are going to be using.\n",
    "\n",
    "Remember that to use the `ImageViewer` class, we only need to call it with an image (and make sure that the image is a `numpy.ndarray`, or a list of such arrays). From there you can change the plotting range, visualize the histogram, get the statistics, browse through the images with the buttons `Next` & `Prev`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7c9b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7218785b1f20b061082a5443d8e5f35",
     "grade": false,
     "grade_id": "cell-43d5c47a7601143e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Declare image_list for ImageViewer\n",
    "image_list = [bikesgray, camera_test]\n",
    "\n",
    "imgs_viewer = viewer(image_list, widgets=True, hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a38db17",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11b77f6ac11550227587f47b066a371b",
     "grade": false,
     "grade_id": "cell-972c615e699738e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Gaussian filter (4 points)\n",
    "[Back to table of contents](#ToC_2_FilteringApplications)\n",
    "\n",
    "In this section you will implement a 2D Gaussian filter with impulse response $h_{\\sigma}[m,n]$, where $\\sigma$ is the standard deviation of an isotropic 2D Gaussian and controls the smoothing strength. This impulse response discretizes the 2D Gaussian function $h_\\sigma(x,y)$ between $[-\\lceil3\\sigma\\rceil,\\lceil 3\\sigma\\rceil]$ in $x$ and $y$. You will **choose the size of the filter to be $N = 2\\lceil 3\\sigma \\rceil+1$** (hence, $N$ is always odd), and you will **ensure your impulse response adds up to $1$** using the appropriate normalization. Here, $\\lceil x \\rceil$ refers to the ceiling function, i.e., the smallest integer larger than a given $x\\in\\mathbb{R}$. \n",
    "\n",
    "Remember that the expression of an [isotropic 2D Gaussian](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) is\n",
    "\n",
    "$$h_\\sigma(x,y) = \\frac{1}{2\\pi\\sigma^2}\\exp\\left(-\\frac{x^2 + y^2}{2\\sigma^2}\\right) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{ y^2}{2\\sigma^2}\\right) \\,.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c5d46",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4500ea73e1bd55d983b991819c3a2c74",
     "grade": false,
     "grade_id": "cell-8d4cb32cef957039",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.A. Implementation of a 2D Gaussian filter (4 points)\n",
    "[Back to table of contents](#ToC_2_FilteringApplications)\n",
    "\n",
    "For **3 points**, implement the function `gaussian(img, sigma)` that convolves an image with a Gaussian filter using a **separable implementation**. If you wish, you can take advantage of the `filter1D` function defined in Section [1.B.](./1_Filtering.ipynb#1.B.-Separable-implementation-(2-points)) and redefined here.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Hint: </b> Remember that you can use <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math\">the <code>Math</code> library</a> to access different mathematical functions (<code>Math.ceil()</code>, <code>Math.floor()</code>, <code>Math.exp()</code>, <code>Math.PI</code>, <code>Math.sqrt()</code>).\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Remember:</b> The first argument to the <code>Image</code> constructor is the <b>height</b> and the second is the <b>width</b>: <code>new Image(height, width)</code> or <code>new Image([height, width])</code>. Feel free to go back to <a href=\"../0_Introductory_lab/Introductory.ipynb#3.-Javascript-image-access-class-(2-points)\">Lab 0: Introduction</a> to review the basic usage of the ImageAccess class.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924fde79",
   "metadata": {
    "deletable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "864630d83f1b0b336b5b373a552403cc",
     "grade": false,
     "grade_id": "cell-2d51a08d09f5db97",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "// function that performs a gaussian filter with sigma on img\n",
    "function gaussian(img, sigma){\n",
    "    // declare output variable\n",
    "    var output = new Image(img.shape());\n",
    "    \n",
    "    // Define normalized 1D mask\n",
    "    // YOUR CODE HERE\n",
    "    \n",
    "    // Filter using separable implementation (hint: your mask should be 1D)\n",
    "    // You can use the filter1D function defined below\n",
    "    // YOUR CODE HERE\n",
    "    \n",
    "    return output\n",
    "}\n",
    "\n",
    "// function that applies a 1D filter\n",
    "function filter1D(img, mask){\n",
    "    // transpose the input variables if necessary\n",
    "    if(img.nx == 1){\n",
    "        img.transposeImage();\n",
    "    }\n",
    "    if(mask.nx == 1){\n",
    "        mask.transposeImage();\n",
    "    }\n",
    "    // create the output image\n",
    "    var output = new Image(img.shape());\n",
    "    // iterate through all pixels\n",
    "    for(var x = 0; x < img.nx; x++){\n",
    "        // get the neighbourhood around position x\n",
    "        var neigh = img.getNbh(x, 0, mask.nx, 1);\n",
    "        // declare a variable to store the values of the convolution. \n",
    "        var val = 0;\n",
    "        // iterate through the neighbourhood\n",
    "        for(var i = 0; i < neigh.nx; i++){\n",
    "            // perform convolution\n",
    "            val += neigh.getPixel(i, 0) * mask.getPixel(mask.nx - 1 - i, 0);\n",
    "        }\n",
    "        // set value in output array\n",
    "        output.setPixel(x, 0, val);\n",
    "    }\n",
    "    return output\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b639144",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b09f5b2ae52bd5b710815c2de79c0417",
     "grade": false,
     "grade_id": "cell-97d95522b0dc505c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have designed a quick test for you to evaluate your method, applying it to a $3 \\times 3$ impulse image. Run the following cell and check that your output has all the desired properties of a Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9707639",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67b0b9af80cda585d06757b79145a9f3",
     "grade": true,
     "grade_id": "cell-f6fe6a1133ee1dc4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "// define the impulse image\n",
    "var impulse = new Image([[0, 0, 0], [0, 1, 0], [0, 0, 0]]);\n",
    "\n",
    "// apply filter to previously defined impulse\n",
    "var impulse_gaussian = gaussian(impulse, 0.5);\n",
    "\n",
    "// look at result, verify that it has the properties of a Gaussian\n",
    "console.log('Your impulse Gaussian:\\n' + impulse_gaussian.visualize());\n",
    "\n",
    "// this assertion checks proper behaviour: that the center is the maximum, and that two pixels in equivalent positions have the same values.\n",
    "if(impulse_gaussian.getPixel(1, 1) < impulse_gaussian.getPixel(1, 2) || impulse_gaussian.getPixel(1, 0) !== impulse_gaussian.getPixel(1, 2)){\n",
    "    console.log('WARNING!!!\\nThere are still some mistakes with your implementation! Look at the sanity checks to understand the mistakes');\n",
    "}else{\n",
    "    console.log('The symmetry of the Gaussian seems good.');\n",
    "}\n",
    "\n",
    "// check normalization\n",
    "var sum = 0\n",
    "for(var x = 0; x < impulse_gaussian.nx; x++){\n",
    "    for (var y = 0; y < impulse_gaussian.ny; y++){\n",
    "        sum += impulse_gaussian.getPixel(x, y);\n",
    "    }\n",
    "}\n",
    "if(Math.abs(sum - 1) > 1e-5){\n",
    "    console.log(\"WARNING!!\\nNormalization not correct\");\n",
    "}else{\n",
    "    console.log(\"Well done! The output sums up to approximately 1.\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694e0784",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2756c24722a5e6c137a42630eef73cd",
     "grade": false,
     "grade_id": "cell-cfb6decc1f440fd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that you have tested your Gaussian filter, apply it to the image `bikesgray`. Use different values of $\\sigma$ (you can change it in the next cell). Look at the evolution of the mean and the standard deviation (you can get them from the statistics box in the `viewer`, or you can use the functions `np.mean` and `np.std`). Then, answer the two multiple choice questions.\n",
    "\n",
    "Run and modify the two following cells to apply Gaussian filters with different $\\sigma$ values to `bikesgray` and view the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a464c",
   "metadata": {
    "kernel": "JavaScript"
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%put bikesgray_gaussian1 bikesgray_gaussian5\n",
    "\n",
    "// apply filter to Image object. To try different sigma values, change the variables or declare more. \n",
    "var bikesgray_gaussian1 = gaussian(new Image(bikesgray), 1).toArray()\n",
    "var bikesgray_gaussian5 = gaussian(new Image(bikesgray), 5).toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d78c8f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Declare parameters for ImageViewer. If you want to visualize more sigma values, update the previous cell and these lists accordingly\n",
    "image_list_blur = [bikesgray, bikesgray_gaussian1, bikesgray_gaussian5]\n",
    "title_list_blur = ['Original', 'Sigma: 1', 'Sigma: 5']\n",
    "# Make sure that the object used is a numpy array\n",
    "for i in range(len(image_list_blur)):\n",
    "    image_list_blur[i] = np.array(image_list_blur[i])\n",
    "\n",
    "# To allow a direct comparison of the images.\n",
    "plt.close('all')\n",
    "blurred_bikesgray_viewer = viewer(image_list_blur, title=title_list_blur, hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae740f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9342155c07639a474343ac70bbb6c7f4",
     "grade": false,
     "grade_id": "cell-91916682701c6590",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multiple Choice Question\n",
    "\n",
    "After modifying the two cells above and visualizing the results, answer the next two questions (worth **0.5 points** each).\n",
    "\n",
    "* Q1: How would you expect the Fourier transform to change?\n",
    "    1. It will show lower values for higher frequencies.\n",
    "    2. It will show higher values for higher frequencies.\n",
    "    3. It will show lower values for lower frequencies.\n",
    "    4. It will not change.\n",
    "\n",
    "\n",
    "* Q2: What will be the output image when $\\sigma\\rightarrow \\infty$? What type of filter would that be?\n",
    "    1. An image equal to the original. It would be an all-pass filter.\n",
    "    2. A constant image. It would be a high-pass filter.\n",
    "    3. A 2D Gaussian. It would be a band-pass filter.\n",
    "    4. A constant image. It would be a low-pass filter.\n",
    "\n",
    "Modify the variables `answer_one` and `answer_two` in the next cell to match your choices. The second and third cells are for you to make sure that your answer is in the valid range (they should not raise any error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4cf9df",
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9aeaa8d2be0e3d4f0f411511df7cd22",
     "grade": false,
     "grade_id": "cell-69433731ec44a141",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Modify these variables\n",
    "answer_one = None\n",
    "answer_two = None\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed32cd3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72ea8111b5071e80c2943f848d3380f7",
     "grade": true,
     "grade_id": "cell-bd0a24f4691d4504",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Sanity test\n",
    "if not answer_one in [1, 2, 3, 4, 5]:\n",
    "    print('WARNING!\\nAnswer one of 1, 2, 3, 4 or 5.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5718fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d069e1cb8dc701e22ade4581b57af04",
     "grade": true,
     "grade_id": "cell-237e0f60231a86f0",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Sanity test\n",
    "if not answer_two in [1, 2, 3, 4]:\n",
    "    print('WARNING!\\nAnswer one of 1, 2, 3 or 4.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d0628",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b25fbb9d42d633da702b3b9adc33fec",
     "grade": false,
     "grade_id": "cell-3c48d28cc833dbf6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.B. Gaussian filter in Python\n",
    "[Back to table of contents](#ToC_2_FilteringApplications)\n",
    "\n",
    "There are several implementations of Gaussian filters in Python. In this section, we will use the `scikit-image` implementation (see its documentation [here](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.gaussian)). The basic syntax is the following:\n",
    "\n",
    "```python\n",
    "output = skimage.filters.gaussian(input, sigma, mode, truncate, preserve_range = True)\n",
    "```\n",
    "\n",
    "The parameters are:\n",
    "* `input` (numpy array): Original image.\n",
    "* `sigma` (float): $\\sigma$ value.\n",
    "* `mode` (string): Boundary conditions. As in the rest of the course, we will be using `'reflect'`. Look carefully at its description in [this link](https://docs.scipy.org/doc/scipy/reference/reference/generated/scipy.ndimage.convolve.html#scipy.ndimage.convolve).\n",
    "* `truncate` (float): truncate the filter at this many standard deviations. Defaults to 4, but **we will use 3** to agree with the implementation in JavaScript.\n",
    "* `preserve_range` (boolean): indicates whether to convert the image to a floating point value between $0$ and $1$ (`False`), or simply normalizing the Gaussian kernel to sum to one (`True`). \n",
    "\n",
    "The output is the filtered image. \n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "<b>Note</b>: In this lab we have presented -and will use- <i>Skimages'</i> implementation of the Gaussian filter because it is more adequate to what we need. However, we encourage you to check out OpenCV's and SciPy's implementation!\n",
    "</div>\n",
    "\n",
    "In the next cells, we will give you an example on the image `bikesgray`. Furthermore, we will compare it to your implementation. Run the next cell to get a blurred version of bikesgray using the skimage gaussian filter. We will use $\\sigma = 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9654e88d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4eefb21882cc5d1c692ce2848405443e",
     "grade": false,
     "grade_id": "cell-fffc82532961afe9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Apply a gaussian filter with sigma=10 to the bikesgray image\n",
    "bikesgray_gaussian_skimage = skimage.filters.gaussian(bikesgray, sigma=10 , mode='reflect', truncate=3, preserve_range=True)\n",
    "gaussian_viewer = viewer(bikesgray_gaussian_skimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e9ce3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37a47ee90622d7e9c01657df05c505e8",
     "grade": false,
     "grade_id": "cell-c91fbdb05c94c533",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, we will compare it to your implementation in JavaScript to make sure that they are equivalent (up to errors on the order of $10^{-14}$). For this, we call the `gaussian` function you implemented with the image bikesgray, also for $\\sigma = 10$. \n",
    "\n",
    "Run the next cell to get the variable `bikesgray_gaussian10`, and the one below it to make the comparison in Python. Note that, if the images are not the same, an `ImageViewer` will pop up, showing you in red the regions that differ the most. If necessary, you can use this information to try to find your mistakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838fb14f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fffb8a5ce625649c6db6bcf7fe91492c",
     "grade": false,
     "grade_id": "cell-d063bc07adab3c79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%put bikesgray_gaussian10\n",
    "\n",
    "// apply filter to Image object\n",
    "var bikesgray_gaussian10 = gaussian(new Image(bikesgray), 10).toArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d2a50c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "233db746f6c5f3c763d5c90e5833ecca",
     "grade": false,
     "grade_id": "cell-005bfe3e8dce7fc8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we will look at each of them and at their differences. Look at the range of values in the histogram to verify the scale of the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb8b99",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0a6dd46d032a3ef16b0f2cff6b87aa4",
     "grade": true,
     "grade_id": "cell-1e8c474739e60ca9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Make sure that the one imported from JavaScript is a numpy array\n",
    "bikesgray_gaussian10 = np.array(bikesgray_gaussian10)\n",
    "\n",
    "# Declare parameters of viewer\n",
    "image_list = [bikesgray_gaussian10, bikesgray_gaussian_skimage, np.abs(bikesgray_gaussian_skimage - bikesgray_gaussian10)]\n",
    "title_list = ['JS', 'Skimage', 'Difference']\n",
    "\n",
    "# We call the viewer with clip_range = [0, 1] to compare the difference with respect to the originals\n",
    "plt.close('all')\n",
    "if not np.allclose(bikesgray_gaussian10, bikesgray_gaussian_skimage):\n",
    "    print('The results of your Gaussian filter do not match Skimage results! Look at the red areas in the viewer to see where you might have gone wrong.')\n",
    "    skimage_gaussian_viewer = viewer([bikesgray_gaussian10, bikesgray_gaussian_skimage], title=['JS', 'Skimage'], widgets=True, compare=True)\n",
    "else :\n",
    "    print('Seems like your Gaussian filter is correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2f61f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "feed285743aa4f88b7fab343c1dcba36",
     "grade": false,
     "grade_id": "cell-60ad1076b1ff17b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2. Application: Super-resolution localization microscopy (3 points)\n",
    "[Back to table of contents](#ToC_2_FilteringApplications)\n",
    "\n",
    "Now that you have implemented several filters and you master the concepts behind digital filtering, we are going to lead you in a real application of Gaussian filtering. You are going to implement a *Basic Localization Tool for Super-resolution Localization Microscopy*, based on the [Difference of Gaussians](https://en.wikipedia.org/wiki/Difference_of_Gaussians) (DoG) filter. From now on, you will only be using Python libraries.\n",
    "\n",
    "In this exercise, we introduce a basic pipeline (see image below) to analyse SMLM images (single-molecule localization microscopy). SMLM is a light microscopy technique which allows to break the famous [Abbe diffraction limit](https://en.wikipedia.org/wiki/Diffraction-limited_system#The_Abbe_diffraction_limit_for_a_microscope) (resolution ~250 nm). SMLM achieves super-resolution performances (resolution ~25 nm) by localising blinking fluorescent molecules (emitters) isolated in different frames (images). To obtain a good reconstruction, SMLM requires a very long sequence (10'000 to 100'000 frames) at very low density of emitters in a frame, 2 to 10 bright spots. The highly contrasted spots are easy to detect and it is possible to localize their center at a sub-pixel accuracy in order to reconstruct a super-resolution map.\n",
    "\n",
    "A good algorithm to detect such spots is to compute the local maximum on the output of the DoG filter ([Difference of Gaussians](https://en.wikipedia.org/wiki/Difference_of_Gaussians)), which is an approximation of the Laplacian-of-Gaussian (LoG) filter explained on _page 5-35_ of the course notes.\n",
    "\n",
    "<table><tr>\n",
    "<td>\n",
    "  <p align=\"center\" style=\"padding: 0px\">\n",
    "    <img alt=\"Localization showcase\" src=\"images/localization_showcase.jpg\" width=\"900\"><br>\n",
    "      <em style=\"color: grey\">SMLM Pipeline: The pipeline starts with centering the mean of the image at $0$. This is followed by a DoG filter, and the local maxima of the result is obtained. Finally, the center of gravity of each image is obtained, and the information is used to construct the high-resolution final image. See the dedicated sections for more details.</em>\n",
    "  </p>\n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "For this exercise, we will use the image sequence `camera`, which consists of 1200 individual frames of single-molecule emitter spots. First of all, let's look at some example frames from the `camera` image sequence. Run the next cell to look at 4 randomly selected frames (you can rerun the cell multiple times to see different frames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a17dfb1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "beb4acf93d4a0131fb66b723c41e2a4a",
     "grade": false,
     "grade_id": "cell-967adfb71fdee751",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Define the zero_mean function, which you already coded in the previous lab, so no need to do it again\n",
    "def zero_mean(img):\n",
    "    return img - np.mean(img)\n",
    "\n",
    "plt.close('all')\n",
    "rand_idx = np.random.randint(0, camera.shape[0]-1, size=4)\n",
    "view = viewer([camera[i] for i in rand_idx], title=[f'camera frame {i}' for i in rand_idx], subplots=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e681e89",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e78213bb69d57da2dbbe19b563d64f6",
     "grade": false,
     "grade_id": "cell-1cea52f0dbc04fea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.A. Difference of Gaussians (1 points)\n",
    "[Back to table of contents](#ToC_2_FilteringApplications)\n",
    "\n",
    "The first step in the localization pipeline is to produce the zero-mean version of each frame. The function `zero_mean`, which takes care of that has already been defined for you in the previous cell. The next step is to implement the [Difference of Gaussians](https://en.wikipedia.org/wiki/Difference_of_Gaussians) filter.\n",
    "\n",
    "The DoG is constructed from the difference between two Gaussian functions, i.e., $\\mathrm{DoG}(x) = h_{\\sigma_{1}}(x) - h_{\\sigma_2}(x)$. It is usually parametrised only by $\\sigma_1$, and $\\sigma_2$ is chosen as $\\sigma_2 = \\sqrt{2}\\sigma_1$. Experiment with the value of $\\sigma_1$ in the next cell to see the kind of profile generated by this filter in 1D (use the slider to do so). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c0e4d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2db4bc1c0142773c29b45270102aab11",
     "grade": false,
     "grade_id": "cell-cbe3da2825307353",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Choose sigmas\n",
    "sigma_slider = widgets.FloatSlider(value=0.5, min=0.5, max=5, description='$\\sigma_1$')\n",
    "\n",
    "# Initialize figure\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(1, 1, num=f\"Difference of Gaussians filter in 1D - SCIPER: {uid}\", figsize=[10,4])\n",
    "ax.plot(0, 0, 0, 0, 0, 0);\n",
    "ax.set_xlabel(r\"$x$\"); plt.legend([r\"$h_{\\sigma_1}(x)$\", r\"$h_{\\sigma_2}(x)$\", r\"$\\mathrm{DoG}_{\\sigma_1}(x)$\"]);\n",
    "ax.set_xlim([-20, 20]); ax.set_ylim([-0.1, 0.8])\n",
    "ax.grid(); fig.tight_layout()\n",
    " \n",
    "# Plotting function - Callback for slider\n",
    "def dog_1d(change):\n",
    "    # Get value of sigma, initialize variables of interest and clear axes\n",
    "    sigma_1 = change.new\n",
    "    sigma_2 = sigma_1*np.sqrt(2)\n",
    "    # Update plot\n",
    "    x = np.arange(-3*sigma_2, (3+6./100)*sigma_2, 6*sigma_2/100)\n",
    "    ax.lines[0].set_data(x, scipy.stats.norm(scale=sigma_1).pdf(x))\n",
    "    ax.lines[1].set_data(x, scipy.stats.norm(scale=sigma_2).pdf(x))\n",
    "    ax.lines[2].set_data(x, scipy.stats.norm(scale=sigma_1).pdf(x) - scipy.stats.norm(scale=sigma_2).pdf(x));\n",
    "\n",
    "sigma_slider.observe(dog_1d, 'value')\n",
    "sigma_slider.value = 1\n",
    "display(sigma_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f236d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4924eb7d69cb3846f26936fec07d424",
     "grade": false,
     "grade_id": "cell-b31e68eb719f0756",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For **1 point**, modify the next cell and write the function `dog`, that takes as input an image and the value of $\\sigma_1$. This function should implement the DoG filter by combining the result of two Gaussian filters. **You should hardcode the value of $\\sigma_2 = \\sigma_1\\sqrt{2}$**. After getting the *DoG*, normalize the output of your function so that it spans the range $[0,1]$.\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "<b>Note</b>: in Section <a href=\"#1.B.-Gaussian-filter-in-Python\">1.B.</a> we presented you the <code>scikit-image</code> implementation of the Gaussian filter, which is simple and clear ($2$ strong points of SciKit-Image). However, as you will see later, OpenCV and SciPy tend to be faster, and have different strong points. Of course we will accept any correct implementation, but we encourage you to find OpenCV's and SciPy's implementations and use the one you prefer! <b>Make sure you use the correct parameters, like <code>preserve_range=True</code> option (or equivalent), truncating the filter at $3\\sigma$ (so $N = 2\\lceil 3\\sigma \\rceil+1$), and using <code>'reflect'</code> or equivalent boundary conditions.</b>\n",
    "</div>\n",
    "\n",
    "Complete the function `dog` in the next cell, where we have also included an initial sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9cce65",
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8a1cef67409d9a0fcb594f0d7f4655d",
     "grade": false,
     "grade_id": "cell-441d0fff5e0e0c7d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "def dog(image, sigma_1):\n",
    "    output = np.zeros(image.shape)\n",
    "    \n",
    "    # Apply the DoG filter to image\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return output\n",
    "\n",
    "if dog(camera_test, 1).max() != 1 or dog(camera_test, 1).min() != 0:\n",
    "    print(\"WARNING: Remember to normalize the output so that it spans the range [0, 1].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9f2a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72b5a052a31117b056f3f7028d11ed32",
     "grade": false,
     "grade_id": "cell-3ba8ad68f5c420f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next two cells, you will visualize the results of your function for different $\\sigma$ values. We will declare a slider with values in the range $[0.2-3]$, a button and an activation function to get the value of the slider and apply your function to an input image. \n",
    "\n",
    "First, run the next cell to declare these widgets and the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b5d44",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73a5654a6b756d5cd87f0fa73dd7f697",
     "grade": true,
     "grade_id": "cell-3b5a0c27111af541",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Define sliders and button\n",
    "sigma_slider = widgets.FloatSlider(value=1, min=0.2, max=3.0, step=0.1, description='\\u03c3\\u2081:')\n",
    "button = widgets.Button(description='Apply DoG')\n",
    "# Define callback function\n",
    "def button_dog(image):\n",
    "    sigma = sigma_slider.value\n",
    "    image = dog(image, sigma)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0052a462",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02d6541d312fd65bb0392d0a97d4b2a3",
     "grade": false,
     "grade_id": "cell-a996be3ef6c3afd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now run the next cell to visualize the results. Go to the menu *Extra Widgets*, where you can find the slider. You will apply it to the image `camera_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-thursday",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60140ecd3d8abb2fcde7676d45bcae95",
     "grade": true,
     "grade_id": "cell-b706ce970a4ec143",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Visualize the dog camera_test\n",
    "plt.close(\"all\")\n",
    "dog_viewer = viewer(camera_test, title=\"DoG camera_test\", new_widgets=[sigma_slider, button], \n",
    "                    callbacks=[button_dog], widgets=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825970a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19e4624567241de1473a3ceef6264158",
     "grade": false,
     "grade_id": "cell-0ce36f18d8882aaf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.B. Local maxima (1 point)\n",
    "[Back to table of contents](#ToC_2_FilteringApplications)\n",
    "\n",
    "Now you will write the function `local_max(img, T)` that returns a binary image. This function will set the pixels which are a local maximum in a $3\\times 3$ neighbourhood to $255$, and any other pixels to $0$. A local maximum is a pixel that has a value strictly greater than its 8 closest neighbors (8-connected) and is strictly greater than a threshold $T$ (specified between $0$ and $1$, relative to the maximum of the image).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <b>Remember:</b> 8-connected pixels are neighbors to every pixel that touches one of their edges or corners.<br>\n",
    "    <table><tr>\n",
    "    <td>\n",
    "      <p align=\"center\" style=\"padding: 0px\">\n",
    "        <img src=\"images/8_connectivity.jpg\" alt=\"8-connectivity\" width=\"100px\"><br>\n",
    "      </p>\n",
    "    </td>\n",
    "    </tr></table>\n",
    "</div>\n",
    "\n",
    "<div class = 'alert alert-success'>\n",
    "<b>Hint</b>: Remember that Image Processing libraries can do most of the work for you. <code>scikit-image</code> has the method <code>skimage.feature.peak_local_max</code> (<a href = 'https://scikit-image.org/docs/0.7.0/api/skimage.feature.peak'>see documentation here</a>), which allows you to specify the size of the neighborhood (through the parameter <code>min_distance</code>, that leads to regions of size <code>2*min_distance+1</code>) and a threshold relative to the maximum value of the image. It outputs the coordinates of the corresponding pixels. Once you have the coordinates, you can use them to index an array and put the desired value in the appropriate places. For example, if we have a NumPy array <code>peaks</code> with local maxima locations as the one returned by the aforementioned function, you can index an image as <code>output[peaks[:,0], peaks[:,1]] = value</code>.\n",
    "    \n",
    "We strongly suggest you use this function. If you are curious about the algorithm, remember that in the documentation of most Python libraries, you can find the <a href = 'https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/peak.py#L119-L326'>source code</a> of a function.\n",
    "</div>\n",
    "    \n",
    "For **1 point**, modify the next cell and define your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d5896f",
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72215b80b50d71e658ffd2fd2553c7d6",
     "grade": false,
     "grade_id": "cell-cf8177b18fdc0486",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Import the module feature from skimage if you are going to use it\n",
    "# Use it as feature.peak_local_max\n",
    "from skimage import feature\n",
    "\n",
    "# Function that computes the local max in a 3x3 nbh\n",
    "def local_max(img, T):\n",
    "    output = np.zeros(img.shape)\n",
    "    \n",
    "    # Apply the local maxima\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9493a6db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ba0a9d54b5bf35bcf9e4b3ddbf1f7bc",
     "grade": false,
     "grade_id": "cell-c5effa4ac055bfb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell for a quick test on your function. In it, we test  that your image applied to `camera_test` with a threshold $T = 0.5$ detects exactly the six maximum points of the image, as it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80ee18",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27b892774f506b2655af7192f3f57a3f",
     "grade": true,
     "grade_id": "cell-9919b9ebd7516650",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "plt.close('all')\n",
    "view = viewer([camera_test, local_max(camera_test, 0.5)], title=['camera_test', 'local maxima'], subplots=(1,2))\n",
    "if np.count_nonzero(local_max(camera_test, 0.5)) == 6:\n",
    "    print('Congratulations! Your function passed this initial sanity check.')\n",
    "else :\n",
    "    print('WARNING!!\\nYour function is not working on the image `camera_tests` as it should.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff7930",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "335249759c2754df58d190b33ac17819",
     "grade": false,
     "grade_id": "cell-03d38256e09cea6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now you are going to see the effect of this function through a slider on the `ImageViewer`. Like in the exercise to visualize the effects of `dog`, we will declare one slider for the threshold and one button to call the `local_max` method. Run the next cell to test it on the image `camera_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a30e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bb274d585f776fd71df2cd421bbe73b",
     "grade": false,
     "grade_id": "cell-a8d24245cf4beb22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "threshold_slider = widgets.FloatSlider(value=0, min=0, max=1, step=0.01, description='T:')\n",
    "button = widgets.Button(description='Apply Local Maxima')\n",
    "\n",
    "def button_local_max(image):\n",
    "    t = threshold_slider.value\n",
    "    image = local_max(image, t)\n",
    "    return image\n",
    "\n",
    "local_max_viewer = viewer(camera_test, title=\"Local Maxima\", new_widgets=[threshold_slider, button], \n",
    "                          callbacks=[button_local_max], widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc69581",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3acf5b6880c0a0183a002e27e99ae60",
     "grade": false,
     "grade_id": "cell-8d953e7467fb74da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.C. Center of gravity (1 point)\n",
    "[Back to table of contents](#ToC_2_FilteringApplications)\n",
    "\n",
    "The most important part of the localization pipeline is the calculation of the center of gravity. This is what allows to **increase the resolution by a factor of 16** in our case. The center of gravity $\\operatorname{c}$ of a $3 \\times 3$ pixel window **centered around the index (0,0)** is calculated as follows:\n",
    "\n",
    "$$\\operatorname{c}(x, y) = \\left(\\frac{\\sum\\limits_{x,y=-1}^{x,y=1}x\\operatorname{w}(x,y)}{\\sum\\limits_{x,y=-1}^{x,y=1}\\operatorname{w}(x,y)}, \\frac{\\sum\\limits_{x,y=-1}^{x,y=1}y\\operatorname{w}(x,y)}{\\sum\\limits_{x,y=-1}^{x,y=1}\\operatorname{w}(x,y)}\\right),$$\n",
    "where $\\operatorname{w}(x,y) = \\operatorname{f}(x,y) - \\operatorname{min}_{x,y=-1}^{x,y=1}(\\operatorname{f}(x,y))$\n",
    "and $\\operatorname{f}(x,y)$ is the $3 \\times 3$ pixel window.\n",
    "\n",
    "<table><tr>\n",
    "<td>\n",
    "  <p align=\"center\" style=\"padding: 0px\">\n",
    "    <img alt=\"Center of gravity\" src=\"images/cog.png\" width=\"200\"><br>\n",
    "  </p>\n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "Remember that using `for` loops in python is very inefficient, so try to avoid them whenever possible. One way to get around using `for` loops to implement the sums in this case is to use the function [`np.meshgrid`](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html) together with [`np.sum`](https://numpy.org/doc/stable/reference/generated/numpy.sum.html). The way we use [`np.meshgrid`](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html) here is to produce the two arrays\n",
    "$$X=\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\text{ and }\n",
    "Y=\n",
    "\\begin{bmatrix}\n",
    "-1 & -1 & -1\\\\\n",
    "0 & 0 & 0\\\\\n",
    "1 & 1 & 1\n",
    "\\end{bmatrix}.$$\n",
    "\n",
    "Think about how you can use these two matrices together with [`np.sum`](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) to avoid `for` loops and **for 1 point** implement the function `cog` in the cell below.\n",
    "<div class='alert alert-info'>\n",
    "    <b>Hint:</b> The center of gravity should be between $-1$ and $+1$ in both directions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d7d56",
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f32627447a1db5b42f7ff67bea3fca80",
     "grade": false,
     "grade_id": "cell-76c906ec9a00f554",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Function that calculates the center of gravity of a 3x3 window\n",
    "def cog(f):\n",
    "    cog_x = 0\n",
    "    cog_y = 0\n",
    "    \n",
    "    # Create coordinate system\n",
    "    X, Y = np.meshgrid([-1, 0, 1], [-1, 0, 1])\n",
    "    \n",
    "    # Calculate center of gravity\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return cog_x, cog_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692f3b16",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c0b3efdf6988784e1123b502bea4ca3",
     "grade": false,
     "grade_id": "cell-41942c538a93b36d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell to perform some simple sanity checks on 4 test windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2ec0a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3434b9b41cf0f5fccc7796b753407d16",
     "grade": true,
     "grade_id": "cell-0e34f6697a741539",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Create test windows\n",
    "test_windows = [np.zeros((3, 3)) for i in range(4)]\n",
    "test_windows[0][0, 0] = 1\n",
    "test_windows[1][2, 2] = 1\n",
    "test_windows[2][1, 1] = 1\n",
    "test_windows[3][1, 1:3] = 1\n",
    "correct_cogs = [(-1.0, -1.0), (1.0, 1.0), (0.0, 0.0), (0.5, 0.0)]\n",
    "# Display test windows\n",
    "plt.close('all')\n",
    "view = viewer(test_windows, title=[f'test window {i}' for i in range(4)], subplots=(2,2))\n",
    "# Check output\n",
    "check = True\n",
    "for i in range(len(test_windows)):\n",
    "    print(f'Cog of test window {i}: {cog(test_windows[i])}')\n",
    "    if not np.allclose(cog(test_windows[i]), correct_cogs[i]):\n",
    "        print(f'WARNING: The cog of test window {i} should be {correct_cogs[i]}.\\n')\n",
    "        check = False\n",
    "if check:\n",
    "    print('\\nNice, your cog function passed the sanity checks.')\n",
    "else :\n",
    "    print('\\nSorry, there are still some errors in your code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9e644",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f97f4741f2ece565fe8389a7bd3ade2",
     "grade": false,
     "grade_id": "cell-e6c5da0b7234e167",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.D. Complete localization pipeline\n",
    "[Back to table of contents](#ToC_2_FilteringApplications)\n",
    "\n",
    "Finally, we'll use the functions you implemented to define the complete localization pipeline. We will also look at the difference between a simple reconstruction without localization and the one that you created now. Run the next cell to define both the `reconstruction` and the `simple_reconstruction` functions, which we already implemented for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85443f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e33fbeb027faa74fb1635c067e15bab3",
     "grade": false,
     "grade_id": "cell-0acb8b07a3c36db6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct(img, sigma_1, T, out_shape=(512, 512)):\n",
    "    out = np.zeros((img.shape[0], out_shape[0], out_shape[1]))\n",
    "    # Calculate size ratio between low-res and high-res image\n",
    "    r_x = out_shape[1] // img.shape[2]\n",
    "    r_y = out_shape[0] // img.shape[1]\n",
    "    \n",
    "    # Apply localization pipeline to each image\n",
    "    for i in range(img.shape[0]):\n",
    "        # Zero mean\n",
    "        img_zm = zero_mean(img[i])\n",
    "        # DoG\n",
    "        img_dog = dog(img_zm, sigma_1)\n",
    "        # Extract coordinates of the local maxima\n",
    "        coords = np.where(local_max(img_dog, T))\n",
    "        # Cog\n",
    "        for i in range(len(coords[0])):\n",
    "            # Calculate center of gravity\n",
    "            cog_x, cog_y = cog(img_zm[coords[0][i]-1:coords[0][i]+2, coords[1][i]-1:coords[1][i]+2])\n",
    "            # Set the corresponding pixel in the high-res image to 255\n",
    "            out[i, int(np.round(coords[0][i] * r_y + cog_y * (3*r_y/2))), \n",
    "                   int(np.round(coords[1][i] * r_x + cog_x * (3*r_x/2)))] = 255\n",
    "    \n",
    "    # Combine all images and threshold\n",
    "    out = np.where(np.sum(out, axis=0) > 0, 255, 0)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def simple_reconstruct(img, sigma_1, T, out_shape=(512, 512)):\n",
    "    img_lm = np.zeros(img.shape)\n",
    "    for i in range(img.shape[0]):\n",
    "        # Detect peaks\n",
    "        img_norm = zero_mean(img[i])\n",
    "        img_dog = dog(img_norm, sigma_1)\n",
    "        img_lm[i] = local_max(img_dog, T)\n",
    "    \n",
    "    # Average peaks\n",
    "    img_avg = np.mean(img_lm, axis=0)\n",
    "    # Resize to higher resolution using cubic interpolation\n",
    "    out = cv.resize(img_avg, dsize=out_shape, interpolation=cv.INTER_CUBIC)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8920f6-01c2-4465-aed8-ed91865411d6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "564bb9861f0d69c039fa3da28a7f8b27",
     "grade": false,
     "grade_id": "cell-5efa879f7edf879c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, run the cell below to visualize both methods and look at the results. **Feel free to experiment with different values for $\\sigma_1$ (DoG) and the threshold $T$ (local max)!** Change the values in the next cell to do so.\n",
    "<div class='alert alert-info'>\n",
    "    <b>Note:</b> The viewer is <code>joint_zoom</code> mode, so you can zoom into both images at the same time and compare them in detail.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea3d57",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Set sigma and threshold\n",
    "sig = 0.8\n",
    "T = 0.5\n",
    "\n",
    "# Perform reconstructions\n",
    "rec_simple = simple_reconstruct(camera, sigma_1=sig, T=T)\n",
    "rec = reconstruct(camera, sigma_1=sig, T=T)\n",
    "plt.close('all')\n",
    "view = viewer([rec_simple, rec], title=['Simple reconstruction', 'Localization reconstruction'], subplots=(1,2), joint_zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c2e332",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a86da216e2b38cc37cadc9d7d506a73",
     "grade": false,
     "grade_id": "cell-908543d737b42d66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "<p><b>Congratulations on finishing Lab 2!</b></p>\n",
    "<p>\n",
    "Make sure to save your notebook (you might want to keep a copy on your personal computer) and upload it to <a href=\"https://moodle.epfl.ch/mod/assign/view.php?id=1111434\">Moodle</a>, in a zip file together with the first part of this lab.\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "* Keep the name of the notebook as: *2_Filtering_Applications.ipynb*,\n",
    "* Name the zip file: *Filtering_lab.zip*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "JavaScript",
     "javascript",
     "JavaScript",
     "#c8e1ae",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.23.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}